\chapter{面向车载边缘计算的VCPS评估指标（Age of View）设计与优化策略研究}
本章主要研究面向车载边缘计算的VCPS评估指标（Age of View）的设计与优化策略。
本章具体内容安排如下：
在\ref{section 3-1}节中，介绍本章的引言，包括车联网中车载信息物理融合系统的研究现状、目前研究存在的不足以及本章的主要贡献。
接着，在\ref{section 3-2}节中，阐述本章的系统架构设计。
为了解决VCPS质量评估问题，\ref{section 3-3}节给出了Age of View（AoV）评估指标的定义，并形式化定义了VCPS质量优化问题。
为解决该问题，\ref{section 3-4}节设计了一种基于差分奖励的多智能体强化学习算法。
为验证所提算法的性能，\ref{section 3-5}节搭建了仿真实验环境并进行了性能验证与分析。
最后，在\ref{section 3-6}节中，对本章的研究工作进行总结。

\section{引言}\label{section 3-1}

传感技术和车联网的最新进展推动了车载信息物理融合系统的发展 \cite{jia2015survey}，
同时，车载信息物理融合系统也成为下一代智能交通系统的关键推动因素。
在VCPS中，交通灯信号、车辆位置、点云数据和监控视频等异质信息可以被车辆协同地感知并上传至边缘节点。
边缘节点基于车辆感知信息进行融合，构建反映车联网中各元素的物理状态，例如车辆的位置、速度和方向，以及交通灯的状态等的逻辑映射，称为视图。
构建逻辑视图所需特定元素由具体的ITS应用决定。
另一方面，车载边缘计算\cite{liu2022fedcpf}是支持高密度车辆通信、海量数据传输和车联网边缘自适应计算卸载的一个具有广阔前景的新兴范式。
因此，研究VEC中高质量的信息物理融合具有重要意义。

研究人员围绕车联网中的数据传播 \cite{liu2021fog, singh2020intent}、信息缓存 \cite{zhang2022digital, dai2020deep, su2018an} 和任务卸载 \cite{shang2021deep, liao2021learning} 方面展开了深入研究。
然而，现有研究工作都没有考虑协同感知和异质信息融合的协同效应。
部分研究人员对VCPS中的预测 \cite{zhang2019a, zhang2020data}、调度 \cite{li2020cyber, lian2021cyber} 和控制 \cite{dai2016a, hu2017cyber, lv2018driving} 技术进行了大量的研究，并促进了各种ITS应用的实现。
尽管如此，上述研究都是基于由边缘/云节点收集足够和可靠的信息的假定。
部分研究聚焦于VCPS中的信息质量评估 \cite{liu2014temporal, dai2019temporal, liu2014scheduling, rager2017scalability, yoon2021performance}。
然而，大部分研究工作只评估了数据项层面的质量，而忽略了对异质信息融合的质量评估。
一些研究专注于车联网中使用深度强化学习的车辆传感和信息融合，但并不适用于多车场景。
少数研究将多智能体DRL应用于车联网中 \cite{kumar2022multi, he2021efficient}。
然而，上述解决方案都不能直接应用于车载信息物理融合系统中的协同感知和异质信息融合。

本章主要解决的关键问题和挑战总结如下。
首先，车联网中物理信息是高度动态的。
因此，考虑感知频率、排队延迟和传输时延的协同效应，以确保信息的新鲜度和时效性是至关重要的。
其次，物理信息是具有时空相关性的。
同时，车辆具有不同的传输能力，并且以分布式方式进行调度。
因此，车辆需要在信息感知和上传方面进行合作，以减少资源消耗并提高信息质量。
再次，V2I 通信具有有限的无线电覆盖范围，并且由于无线通信的自身性质而并不可靠。
因此，降低上传过程中的间歇性连接和数据包丢失的影响也非常关键。
最后，物理信息在分布、更新频率和模式方面具有内在的异质性，这些异质特征同样给信息融合的质量建模带来了巨大挑战。

基于以上分析，本章共同研究了评估指标和调度算法，旨在通过协同感知和异质信息融合来提高VCPS的质量。
本章节主要的贡献概述如下。
第一，通过整合异质信息的感知、上传、建模和评估，研究了面向车载边缘计算的车载信息物理融合系统质量评估问题。
特别地，在多类M/G/1优先级队列和香农理论的基础上，建立了一个协同感知模型。
在此基础上，设计了一个新的指标，称为Age of View，用于评估VCPS中异质信息的时效性、完整性和一致性。
本章是首次定量评估VCPS质量并考虑了新设计的AoV指标的独特特性的工作。
第二，提出了一个基于差分奖励的多智能体深度强化学习（Multi-Agent Difference-Reward-based Deep Reinforcement Learning, MADR）算法。
具体地说，车辆作为独立的智能体，具有感知频率和上传优先权的动作空间。
然后，设计了一个基于差分奖励（Difference Reward, DR）的信用分配方案来评估各个车辆对视图构建的贡献，从而提高每个智能体的行动的评估精度。
此外，与传统的DRL算法相比，该方案能够实现每个智能体的较小动作空间，并加快收敛速度。
同时，根据车辆轨迹和视图要求，在边缘节点设计了一个V2I带宽分配（V2I Bandwidth Allocation, VBA）方案。
第三，基于现实世界的车辆轨迹，进行了全面的性能评估。
MADR和四种竞争性算法，包括随机分配（Random Allocation, RA）、集中式深度确定性策略梯度（Centralized Deep Deterministic Policy Gradient，C-DDPG）\cite{mlika2022deep}、多智能体行动者-评论家（Multi-Agent Actor-Critic，MAAC）\cite{he2021efficient}和采用VBA策略的MAAC（MAAC-VBA），都得到了实现。
仿真结果表明，在最大限度地提高VCPS质量方面，所提出的方案比RA、C-DDPG、MAAC和MAAC-VBA分别高出约61.8\%、23.8\%、22.0\%和8.0\%，与C-DDPG、MAAC和MAAC-VBA相比，收敛速度分别加快了约6.8倍、1.4倍和1.3倍。

